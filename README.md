# Netflix Data Analysis ğŸ¬

> A comprehensive data science project analyzing Netflix titles using exploratory data analysis (EDA), machine learning classification, regression modeling, and time series forecasting.

## Project Overview

This project provides a **structured, progressive learning path** through essential data science techniques using Netflix's real-world content dataset. The analysis is organized into **three difficulty levels**, each building on fundamental concepts to explore increasingly advanced methodologies and machine learning algorithms.

Whether you're a beginner learning data science fundamentals or an intermediate practitioner honing your skills, this project offers hands-on experience with real-world datasets and industry-standard techniques.

## Dataset ğŸ“Š

**Source:** Netflix Titles Dataset (Available on Kaggle)

| Property           | Value                                                                                     |
| ------------------ | ----------------------------------------------------------------------------------------- |
| **Format**         | CSV                                                                                       |
| **Location**       | `data/netflix_titles.csv`                                                                 |
| **Total Records**  | 8,000+ titles                                                                             |
| **Key Attributes** | Type, Title, Director, Cast, Country, Release Year, Rating, Duration, Genres, Description |

### Key Columns

- **`show_id`** - Unique identifier for each title
- **`type`** - Content type: Movie or TV Show
- **`title`** - Official content title
- **`director`** - Director(s) of the content
- **`cast`** - Lead cast members
- **`country`** - Production country/countries
- **`date_added`** - Date content was added to Netflix
- **`release_year`** - Original release year
- **`rating`** - Content rating (G, PG, PG-13, R, TV-14, TV-MA, etc.)
- **`duration`** - Duration in minutes (movies) or number of seasons (TV shows)
- **`listed_in`** - Genre(s) assigned to the content
- **`description`** - Plot summary or content description

## Project Structure ğŸ“

```
Netflix Data Analysis/
â”‚
â”œâ”€â”€ ğŸ“„ README.md                              # Project documentation (this file)
â”œâ”€â”€ ğŸ“„ data/
â”‚   â””â”€â”€ netflix_titles.csv                    # Netflix dataset (8,000+ titles)
â”‚
â”œâ”€â”€ ğŸ“ level1/  [Fundamentals]
â”‚   â”œâ”€â”€ 01_EDA_Data_Exploration.ipynb         # Data cleaning & visualization
â”‚   â””â”€â”€ 02_ML_Classification.ipynb            # Logistic Regression classifier
â”‚
â”œâ”€â”€ ğŸ“ level2/  [Intermediate]
â”‚   â””â”€â”€ 03_Regression_and_Clustering.ipynb    # Regression, ensemble methods & clustering
â”‚
â””â”€â”€ ğŸ“ level3/  [Advanced]
    â””â”€â”€ 04_ARIMA_Time_Series_Forecasting.ipynb  # Time series analysis & forecasting
```

## Level-by-Level Breakdown ğŸ“š

### Level 1: Fundamentals ğŸŒ±

Master the essentials of data science with comprehensive EDA and your first machine learning model.

#### **Notebook 1: EDA Data Exploration**

[`level1/01_EDA_Data_Exploration.ipynb`](level1/01_EDA_Data_Exploration.ipynb)

Explore, understand, and visualize the Netflix dataset:

- âœ“ Load and inspect the dataset structure
- âœ“ Handle missing values in director, cast, and country columns
- âœ“ Feature engineering (convert date_added to year_added)
- âœ“ Visualize content distribution: Movies vs TV Shows
- âœ“ Analyze trends by genre, rating, and release year
- âœ“ Generate summary statistics and identify key patterns
- âœ“ Create meaningful visualizations with matplotlib/seaborn

**Core Skills Covered:**

- Data loading and inspection (pandas)
- Missing value analysis and handling strategies
- Data type conversions and feature engineering
- Exploratory data analysis (EDA)
- Data visualization best practices
- Statistical summary and interpretation

---

#### **Notebook 2: ML Classification**

[`level1/02_ML_Classification.ipynb`](level1/02_ML_Classification.ipynb)

Build your first machine learning model to classify content type:

- âœ“ Prepare data for modeling (encode categorical variables)
- âœ“ Feature engineering (extract numeric features from duration)
- âœ“ One-hot encode categorical features (genres, ratings)
- âœ“ Perform train-test split (80-20 ratio)
- âœ“ Train a Logistic Regression classifier
- âœ“ Classify content as Movie vs TV Show
- âœ“ Evaluate model performance (accuracy, precision, recall)

**Core Skills Covered:**

- Data preprocessing and feature engineering
- Categorical encoding techniques
- Train-test splitting and cross-validation concepts
- Logistic Regression classifier
- Model evaluation metrics
- scikit-learn fundamentals

---

### Level 2: Intermediate ğŸš€

Advance your skills with multiple supervised and unsupervised learning techniques.

#### **Notebook 3: Regression and Clustering**

[`level2/03_Regression_and_Clustering.ipynb`](level2/03_Regression_and_Clustering.ipynb)

Explore multiple machine learning algorithms in one comprehensive notebook:

**Task 1: Regression Analysis**

- Predict content duration using features like release year, rating, type, and genre
- Preprocess features and handle categorical variables
- Train and evaluate regression models
- Calculate performance metrics (Mean Squared Error, RÂ² Score)
- Interpret regression results

**Task 2: Advanced Classification**

- Implement multi-class classification problems
- Train a Random Forest Classifier for improved accuracy
- Compare model performance with baseline models
- Analyze feature importance to understand model decisions
- Apply ensemble learning concepts

**Task 3: Clustering Analysis**

- Segment Netflix content using K-Means clustering
- Apply Principal Component Analysis (PCA) for dimensionality reduction
- Visualize clusters in 2D/3D space
- Interpret and characterize different content segments
- Determine optimal number of clusters

**Core Skills Covered:**

- Regression modeling and evaluation
- Ensemble methods (Random Forest)
- Unsupervised learning and clustering
- Principal Component Analysis (PCA)
- Feature importance analysis
- Advanced model evaluation techniques

---

### Level 3: Advanced ğŸ”¬

Master time series analysis and forecasting with state-of-the-art techniques.

#### **Notebook 4: ARIMA Time Series Forecasting**

[`level3/04_ARIMA_Time_Series_Forecasting.ipynb`](level3/04_ARIMA_Time_Series_Forecasting.ipynb)

Analyze temporal patterns and forecast future trends:

- âœ“ Parse and prepare time series data (date_added column)
- âœ“ Aggregate data into monthly time series
- âœ“ Perform stationarity testing (Augmented Dickey-Fuller test)
- âœ“ Decompose time series into trend, seasonality, and residuals
- âœ“ Apply moving average smoothing techniques
- âœ“ Build and train ARIMA models with appropriate parameters
- âœ“ Generate forecasts for future content additions
- âœ“ Validate model performance using error metrics (MSE, MAE)

**Core Skills Covered:**

- Time series data preparation and exploration
- Stationarity testing and differencing
- Time series decomposition (trend, seasonality, residuals)
- ARIMA (AutoRegressive Integrated Moving Average) modeling
- Parameter selection (p, d, q values)
- Time series forecasting and validation
- statsmodels library expertise

---

## Installation & Setup ğŸ”§

### Prerequisites

- **Python** 3.8 or higher
- **Jupyter Notebook** or **JupyterLab**
- Package manager: `pip` or `conda`

### Required Libraries

| Library          | Purpose                                       |
| ---------------- | --------------------------------------------- |
| **pandas**       | Data manipulation and analysis                |
| **numpy**        | Numerical computing                           |
| **matplotlib**   | Static and interactive visualizations         |
| **seaborn**      | Statistical data visualization                |
| **scikit-learn** | Machine learning algorithms                   |
| **statsmodels**  | Statistical modeling and time series analysis |
| **scipy**        | Scientific computing utilities                |

### Installation Steps

1. **Clone or download the project:**

   ```bash
   cd "your project location"
   ```

2. **Create a virtual environment (recommended):**

   ```bash
   python -m venv venv
   venv\Scripts\activate  # On Windows
   # or: source venv/bin/activate  # On macOS/Linux
   ```

3. **Install required packages:**

   ```bash
   pip install pandas numpy matplotlib seaborn scikit-learn statsmodels scipy
   ```

   Or install all at once:

   ```bash
   pip install -r requirements.txt
   ```

### Running the Notebooks

1. **Start Jupyter:**

   ```bash
   jupyter notebook
   ```

2. **Follow this learning path:**
   - ğŸŒ± Start with [`level1/01_EDA_Data_Exploration.ipynb`](level1/01_EDA_Data_Exploration.ipynb)
   - ğŸŒ± Then [`level1/02_ML_Classification.ipynb`](level1/02_ML_Classification.ipynb)
   - ğŸš€ Progress to [`level2/03_Regression_and_Clustering.ipynb`](level2/03_Regression_and_Clustering.ipynb)
   - ğŸ”¬ Complete with [`level3/04_ARIMA_Time_Series_Forecasting.ipynb`](level3/04_ARIMA_Time_Series_Forecasting.ipynb)

3. **Execute cells in order** and read the explanatory comments throughout each notebook.

## Techniques & Algorithms ğŸ› ï¸

### Comprehensive Technique Matrix

| Technique                           | Difficulty | Notebook            | Description                                              |
| ----------------------------------- | ---------- | ------------------- | -------------------------------------------------------- |
| **Data Cleaning**                   | â­         | EDA                 | Handle missing values, data validation, type conversion  |
| **Exploratory Data Analysis (EDA)** | â­         | EDA                 | Data profiling, visualization, pattern discovery         |
| **Statistical Analysis**            | â­         | EDA                 | Summary statistics, distributions, correlations          |
| **Feature Engineering**             | â­â­       | EDA, Classification | Create meaningful features from raw data                 |
| **Categorical Encoding**            | â­â­       | Classification      | One-hot encoding, label encoding, ordinal encoding       |
| **Train-Test Splitting**            | â­â­       | Classification      | Data partitioning for model validation                   |
| **Logistic Regression**             | â­â­       | Classification      | Binary classification algorithm                          |
| **Regression Modeling**             | â­â­       | Regression          | Linear & polynomial regression for continuous prediction |
| **Random Forest Classification**    | â­â­â­     | Regression          | Ensemble learning for improved accuracy                  |
| **K-Means Clustering**              | â­â­â­     | Clustering          | Unsupervised segmentation algorithm                      |
| **PCA & Dimensionality Reduction**  | â­â­â­     | Clustering          | Reduce features while preserving variance                |
| **Time Series Decomposition**       | â­â­â­     | ARIMA               | Separate trend, seasonality, and residuals               |
| **Stationarity Testing (ADF)**      | â­â­â­     | ARIMA               | Test and transform time series for ARIMA                 |
| **ARIMA Forecasting**               | â­â­â­     | ARIMA               | AutoRegressive Integrated Moving Average modeling        |
| **Model Evaluation Metrics**        | â­â­â­     | All                 | Accuracy, precision, recall, F1, MSE, MAE, RMSE          |

## Learning Outcomes âœ…

By completing this project, you will master:

### Foundational Skills

- âœ… Data cleaning and handling missing values
- âœ… Exploratory data analysis (EDA) techniques
- âœ… Data visualization best practices
- âœ… Statistical analysis and interpretation

### Machine Learning Skills

- âœ… Feature engineering and preprocessing
- âœ… Supervised learning (classification & regression)
- âœ… Unsupervised learning (clustering, dimensionality reduction)
- âœ… Ensemble methods for improved model performance
- âœ… Model evaluation and validation strategies

### Advanced Analytics Skills

- âœ… Time series analysis and decomposition
- âœ… Forecasting with ARIMA models
- âœ… Parameter tuning and hyperparameter optimization
- âœ… Interpretation of machine learning results

### Professional Development

- âœ… End-to-end machine learning workflows
- âœ… Best practices in data science projects
- âœ… Reproducible analysis with random state management
- âœ… Clear code documentation and commenting

## Key Questions to Explore ğŸ”

This project helps answer important business and analytical questions:

1. **Content Growth & Strategy**
   - How has Netflix content volume evolved over time?
   - What is the trend in content additions (increasing, decreasing, seasonal)?
   - When did Netflix add the most content to its platform?

2. **Content Composition**
   - What proportion of Netflix's library is movies vs TV shows?
   - What are the most common content ratings on the platform?
   - How has the rating distribution changed over time?

3. **Content Characteristics**
   - Can we predict content duration from other features?
   - What features are most predictive of content type?
   - How do genres and ratings relate to content type?

4. **Content Segmentation**
   - Can we meaningfully segment Netflix content into clusters?
   - What characteristics define each cluster?
   - How do audience-facing genres relate to algorithmic clusters?

5. **Future Forecasting**
   - Can we predict Netflix's future content additions?
   - Are there seasonal patterns in content releases?
   - What are the expected trends for the next quarter/year?

## Technologies Used ğŸ’»

### Data Science Stack

| Category             | Tools                             |
| -------------------- | --------------------------------- |
| **Data Processing**  | Pandas, NumPy, SciPy              |
| **Machine Learning** | scikit-learn                      |
| **Time Series**      | statsmodels                       |
| **Visualization**    | Matplotlib, Seaborn               |
| **Environment**      | Jupyter Notebook/Lab, Python 3.8+ |

### Key Libraries & Versions

```
pandas >= 1.3.0        # Data manipulation and analysis
numpy >= 1.20.0        # Numerical computing
matplotlib >= 3.4.0    # Static and interactive plotting
seaborn >= 0.11.0      # Statistical data visualization
scikit-learn >= 0.24.0 # Machine learning algorithms
statsmodels >= 0.13.0  # Statistical models and tests
scipy >= 1.7.0         # Scientific computing
```

## Project Notes ğŸ“

### Code Quality & Best Practices

- âœ“ Each notebook is **self-contained** with clear, sequential workflow
- âœ“ **Inline comments** explain each step and why it's performed
- âœ“ **Markdown cells** provide context and learning objectives
- âœ“ Data preprocessing and feature engineering embedded for educational clarity
- âœ“ Models trained with **`random_state=42`** for reproducibility across runs
- âœ“ Functions are modular and can be adapted for similar datasets

### Dataset Notes

- The dataset contains some missing values (director, cast, country) which are handled appropriately in each notebook
- Duration is formatted differently for movies (minutes) vs TV shows (seasons)
- Content may have multiple genres separated by commas

### Reproducibility

All notebooks use fixed random seeds to ensure consistent results across multiple runs:

```python
np.random.seed(42)
random.seed(42)
from sklearn.model_selection import train_test_split
train_test_split(..., random_state=42)
```

### Recommended Environment

- **OS:** Windows, macOS, or Linux
- **Python:** 3.8, 3.9, or 3.10
- **RAM:** 4GB minimum (8GB+ recommended)
- **Disk:** 500MB free space for dataset and notebooks

## Troubleshooting ğŸ› ï¸

### Common Issues & Solutions

| Issue                               | Solution                                               |
| ----------------------------------- | ------------------------------------------------------ |
| **ModuleNotFoundError**             | Install missing packages: `pip install <package_name>` |
| **Jupyter not found**               | Install Jupyter: `pip install jupyter`                 |
| **Dataset file not found**          | Ensure `netflix_titles.csv` is in the `data/` folder   |
| **Memory errors on large datasets** | Reduce data or increase available RAM                  |
| **Plot display issues**             | Add `%matplotlib inline` at the start of notebooks     |
| **Random state not working**        | Ensure `random_state` parameter is set in all models   |

### Helpful Tips

- **Progressive Execution:** Always run notebook cells in order from top to bottom
- **Kernel Reset:** If you encounter errors, try "Kernel â†’ Restart & Clear Output"
- **Variable Inspection:** Use `print()` or `df.head()` to inspect intermediate results
- **Help Documentation:** Use `help(function_name)` or `function_name?` in Jupyter cells

---

## Quick Start Guide ğŸš€

**Fastest way to get started:**

```bash
# 1. Navigate to project
cd "your project location"

# 2. Create virtual environment
python -m venv venv
venv\Scripts\activate

# 3. Install dependencies
pip install pandas numpy matplotlib seaborn scikit-learn statsmodels

# 4. Launch Jupyter
jupyter notebook

# 5. Open level1/01_EDA_Data_Exploration.ipynb and start learning!
```

---

## License & Attribution ğŸ“„

This educational project is provided **as-is** for learning and educational purposes. The Netflix dataset used is sourced from publicly available data and is used here for educational demonstration.

### Attribution

- **Project:** Netflix Data Analysis - Data Science Learning Path
- **Dataset:** Netflix Titles (Kaggle)
- **Purpose:** Educational - Data Science & Machine Learning Training

### Fair Use

This project demonstrates data science techniques on a real-world dataset. For any production use or redistribution of the dataset, please refer to the original dataset's terms of use on Kaggle.

---

## Contributing ğŸ¤

Have ideas for improvements? Found a bug? Feel free to:

- Report issues with notebook execution
- Suggest additional analysis or techniques
- Improve documentation or explanations
- Optimize code for clarity and performance

---

## Connect & Learn More ğŸ“–

### Next Steps After Completing This Project

1. **Apply to new datasets** - Use the same techniques on Kaggle datasets
2. **Explore advanced topics** - Deep learning, neural networks, NLP
3. **Build portfolio projects** - Create your own end-to-end analyses
4. **Join communities** - Engage with other data scientists on Kaggle, GitHub

### Related Resources

- [Kaggle Datasets](https://www.kaggle.com/datasets) - Find more datasets
- [Scikit-learn Documentation](https://scikit-learn.org/) - ML library reference
- [Statsmodels Guide](https://www.statsmodels.org/) - Time series guide
- [Matplotlib & Seaborn](https://matplotlib.org/) - Visualization tutorials

---

## Project Statistics ğŸ“Š

- **Total Notebooks:** 4
- **Total Learning Levels:** 3
- **Estimated Time to Complete:** 10-15 hours
- **Difficulty Progression:** Beginner â†’ Advanced
- **Hands-on Coding:** 100%

---

## Start Your Data Science Journey! ğŸ¬

**Begin here:** Open [`level1/01_EDA_Data_Exploration.ipynb`](level1/01_EDA_Data_Exploration.ipynb) in Jupyter and start exploring the Netflix dataset!

> "The best way to learn data science is by doing. This project gives you the real-world experience you need." - Happy Learning! ğŸš€
