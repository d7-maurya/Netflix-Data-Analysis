{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8011fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for data analysis, ML, and visualization\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Import ML components: data splitting, preprocessing, models, and metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, roc_curve, auc\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Set figure size for better visualization\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Load Netflix dataset\n",
    "df = pd.read_csv('../data/netflix_titles.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659b0488",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef8ef21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Level 2 - Task 1: Regression to predict content duration\n",
    "# Prepare regression data with relevant features\n",
    "reg_df = df[['duration', 'release_year', 'rating', 'type', 'listed_in']].dropna()\n",
    "\n",
    "# Extract numeric duration values (remove units like \"min\" or \"Seasons\")\n",
    "reg_df['duration_num'] = reg_df['duration'].str.extract('(\\d+)').astype(int)\n",
    "\n",
    "# Encode categorical variable: Movie=0, TV Show=1\n",
    "reg_df['type'] = reg_df['type'].map({'Movie': 0, 'TV Show': 1})\n",
    "\n",
    "# One-hot encode rating categories to make them compatible with ML models\n",
    "reg_df = pd.get_dummies(reg_df, columns=['rating'], drop_first=True)\n",
    "\n",
    "# Display prepared data\n",
    "reg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e9a40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target variable\n",
    "X = reg_df.drop(['duration', 'duration_num', 'listed_in'], axis=1)\n",
    "y = reg_df['duration_num']\n",
    "\n",
    "# Split data into training and testing sets (80-20 split)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Build and train Linear Regression model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on test set\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "# Evaluate model using Mean Squared Error and R² score\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Display results\n",
    "mse, r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a41e76",
   "metadata": {},
   "source": [
    "In this task, a regression model was developed to predict the duration of Netflix titles based on content attributes.\n",
    "Linear Regression was used as a baseline model, and its performance was evaluated using Mean Squared Error (MSE) and R² score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d8274f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2: Classification - Predict Movie vs TV Show\n",
    "# Exploratory Data Analysis (EDA)\n",
    "df.info()\n",
    "# Count distribution of content types\n",
    "df['type'].value_counts()\n",
    "# Visualize distribution\n",
    "sns.countplot(x='type', data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de530c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data cleaning and preprocessing\n",
    "# Select relevant features for classification\n",
    "df = df[['type', 'release_year', 'duration', 'rating', 'country']]\n",
    "# Remove rows with missing values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Extract numeric duration from duration column\n",
    "df['duration'] = df['duration'].str.extract('(\\d+)').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bb510e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display cleaned dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84bf914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables to numeric values\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Encode type: Movie=0, TV Show=1\n",
    "df['type'] = le.fit_transform(df['type'])\n",
    "# Encode rating categories\n",
    "df['rating'] = le.fit_transform(df['rating'])\n",
    "# Encode country categories\n",
    "df['country'] = le.fit_transform(df['country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a4ac40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling and target separation\n",
    "# Separate features and target variable\n",
    "X = df.drop('type', axis=1)\n",
    "y = df['type']\n",
    "\n",
    "# Scale features to have mean=0 and std=1 for better model performance\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760006f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split scaled data into training and testing sets (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662e702e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Logistic Regression model for binary classification\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "# Make predictions on test set\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8767ee94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model performance using multiple metrics\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "# Display confusion matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0022901b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and visualize ROC curve to assess model discrimination ability\n",
    "# Get probability predictions for positive class\n",
    "y_prob = model.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Calculate false positive rate, true positive rate, and AUC\n",
    "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.plot(fpr, tpr, label=f\"AUC = {roc_auc:.2f}\")\n",
    "plt.plot([0,1], [0,1], linestyle='--')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f256cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest model for comparison\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate\n",
    "rf_pred = rf.predict(X_test)\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, rf_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0b179a",
   "metadata": {},
   "source": [
    "Title\n",
    "\n",
    "Classification of Netflix Content Using Logistic Regression\n",
    "\n",
    "Objective\n",
    "\n",
    "The objective of this project is to build a classification model using Logistic Regression to predict whether a Netflix title is a Movie or a TV Show.\n",
    "\n",
    "Dataset Description\n",
    "\n",
    "A publicly available Netflix dataset containing information such as release year, duration, rating, and country was used.\n",
    "\n",
    "Methodology\n",
    "\n",
    "Data cleaning and preprocessing\n",
    "\n",
    "Encoding categorical variables\n",
    "\n",
    "Feature scaling\n",
    "\n",
    "Train-test split\n",
    "\n",
    "Logistic Regression model training\n",
    "\n",
    "Performance evaluation using accuracy, precision, recall, and ROC curve\n",
    "\n",
    "Comparison with Random Forest classifier\n",
    "\n",
    "Results\n",
    "Logistic Regression achieved good classification accuracy.\n",
    "\n",
    "ROC-AUC score indicated strong class separation.\n",
    "\n",
    "Random Forest slightly outperformed Logistic Regression but lacked interpretability.\n",
    "\n",
    "Conclusion\n",
    "\n",
    "Logistic Regression proved effective for classifying Netflix content types. The model is simple, interpretable, and suitable for binary classification tasks. Future improvements can include feature engineering and advanced NLP techniques.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35104c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3: Clustering - Group Netflix content based on characteristics\n",
    "# Data preprocessing for clustering\n",
    "df = df[['release_year', 'duration', 'rating', 'country']]\n",
    "# Remove missing values\n",
    "df.dropna(inplace=True)\n",
    "# Extract numeric duration\n",
    "df['duration'] = df['duration'].str.extract('(\\d+)').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed39b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables (rating, country) to numeric\n",
    "le = LabelEncoder()\n",
    "df['rating'] = le.fit_transform(df['rating'])\n",
    "df['country'] = le.fit_transform(df['country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2367fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features for clustering (important for K-Means)\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609c5e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elbow method: find optimal number of clusters using WCSS (Within-Cluster Sum of Squares)\n",
    "wcss = []\n",
    "\n",
    "for k in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(scaled_data)\n",
    "    wcss.append(kmeans.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab3e0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot elbow curve to visualize optimal cluster number\n",
    "plt.plot(range(1, 11), wcss, marker='o')\n",
    "plt.xlabel(\"Number of Clusters\")\n",
    "plt.ylabel(\"WCSS\")\n",
    "plt.title(\"Elbow Method for Optimal K\")\n",
    "plt.show()\n",
    "\n",
    "# Apply K-Means with optimal number of clusters (k=3)\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "clusters = kmeans.fit_predict(scaled_data)\n",
    "\n",
    "# Add cluster assignments to dataframe\n",
    "df['Cluster'] = clusters\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00ec781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize clusters using PCA (Principal Component Analysis) for dimensionality reduction\n",
    "pca = PCA(n_components=2)\n",
    "pca_data = pca.fit_transform(scaled_data)\n",
    "\n",
    "# Plot 2D scatter plot with cluster colors\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(pca_data[:,0], pca_data[:,1], c=clusters)\n",
    "plt.xlabel(\"PCA Component 1\")\n",
    "plt.ylabel(\"PCA Component 2\")\n",
    "plt.title(\"Netflix Content Clustering\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0361c992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display cluster characteristics (mean values of features for each cluster)\n",
    "df.groupby('Cluster').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84288173",
   "metadata": {},
   "source": [
    "Title\n",
    "\n",
    "Clustering Netflix Content Using K-Means\n",
    "\n",
    "Objective\n",
    "\n",
    "To group Netflix titles into meaningful clusters using unsupervised learning techniques.\n",
    "\n",
    "Methodology\n",
    "\n",
    "Data cleaning and preprocessing\n",
    "\n",
    "Feature encoding and scaling\n",
    "\n",
    "Optimal cluster selection using Elbow Method\n",
    "\n",
    "K-Means clustering\n",
    "\n",
    "Dimensionality reduction using PCA for visualization\n",
    "\n",
    "Results\n",
    "\n",
    "Netflix content was grouped into three clusters.\n",
    "\n",
    "Each cluster represents different content patterns based on duration, release year, and regional distribution.\n",
    "\n",
    "PCA visualization clearly shows cluster separation.\n",
    "\n",
    "Conclusion\n",
    "\n",
    "K-Means clustering effectively segmented Netflix content into meaningful groups. This approach can be used for recommendation systems and content analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
